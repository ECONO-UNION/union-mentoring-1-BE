# Memory Management

----

>## Mentor's Q
>
>### 1. 과거 우리는 메인 메모리에 여러 프로세스를 로드하기위해 메모리를 파티션으로 나누어 프로세스를 로드하는 방식인 파티셔닝 기법을 사용하였다. 그렇다면 파티셔닝(동적, 정적) 기법으로 프로세스에 메모리를 할당할 때 생기는 문제점은 무엇이고 어떤 해결방법이 있는가?
>
>
>
>### 2. 단편화를 해결하는 방법 중 하나인 Compaction은 많은 오버헤드를 발생시킨다고 알려져있다. Compaction과 달리 많은 오버헤드를 발생시키지 않고 외부 단편화를 극적으로 없애는 기법은 Paging 기법인데 이 기법이 나오게 된 이유와, 원리, 장단점에 대해서 설명해주세요.
>
>
>
>### 3. 메모리를 물리적이 아닌 논리적 내용의 단위인 세그먼트로 분할하여 메모리를 관리하는 기법인 Memory Segmentation에 대해서 알려주시고, Paging 기법이랑 비교해주세요
>
>
>
>### 4. 가상 메모리는 무엇이고 왜 나오게 되었나요? 그리고 이를 통해 우리는 무엇을 할 수 있을까요?
>
>
>
>### 5. 가상 메모리 시스템에서 자주 사용되는 기법 중 하나인 Demand Paging은 무엇이고 왜 사용하게 되었으며 Demand Paging의 핵심 알고리즘인 페이지 교체 알고리즘에 대해서 장단점을 포함해 소개해주세요. 

[toc]

## 1. 메모리는 무엇인가 ? 

컴퓨터 메모리는 이진 형식으로 표현되는 일부 데이터의 모음을 말한다. 정보나 데이터를 일시적으로 또는 영구적으로 저장 할 수 있는 컴퓨터 장치를 우리는 저장 장치라고 부른다.

**데이터는 컴퓨터 시스템에 어떻게 저장 되나 ?**

-> 메모리 관리를 이해하기 위해 데이터가 컴퓨터 시스템에 저장되는 방식에 대한 모든 것을 명확하게 이해해야한다. 기계는 0또는 1 이진언어만 이해하는데, 컴퓨터는 모든 데이터를 먼저 이진 언어로 변환한 다음 메모리에 저장 하게 된다.

즉, int a = 10으로 작성된 프로그램 라인이 있는 경우 컴퓨터는 이를 이진 언어로 변환한 뒤에 메모리 블록에 저장한다.

![image-20210916183007133](/Users/samuel/Library/Application Support/typora-user-images/image-20210916183007133.png)

10의 이진 표현은 1010이고, 여기에서는 32비트 시스템을 나타내고 있기 때문에 int의 크기는 2바이트 , 16비트 이다. 1 메모리 블록은 1비트를 저장하게 된다. 부호 있는 정수를 사용하는 경우 메모리의 최상위 비트는 항상 부호 있는 비트가 된다. 부호 있는 비트 값 0은 양의 정수를 나타내고 1은 음의 정수를 나타낸다. 여기서 메모리 어레이를 사용하여 저장할 수 있는 값의 범위는 -32768 ~ 32767이 된다.

CPU는 시스템의 ㅜㅈ 메모리, 레지스터 및 캐시에 직접 접근할 수 있는데, 프로그램은 항상 주 메모리에서 실행된다. 메인 메모리의 크기는 현존하는 대부분의 멀티 프로그래밍에 영향을 미친다. 메인 메모리의 크기가 CPU보다 크게 되면 메인 메모리에 동시에 더 많은 프로세스를 로드 할 수 있으며, CPU 활용도는 물론 멀티 프로그래밍의 정도가 증가하게 된다. 

> Let's consider,  
>
> Process Size = 4 MB 
>
> Main memory size = 4 MB  
>
> The process can only reside in the main memory at any time.  
>
> If the time for which the process does IO is P,  
>
>  
>
> Then,  
>
>  
>
> CPU utilization = (1-P)  
>
> let's say,  
>
> P = 70%  
>
> CPU utilization = 30 %  
>
> Now, increase the memory size, Let's say it is 8 MB.  
>
> Process Size = 4 MB  
>
> Two processes can reside in the main memory at the same time.  
>
> Let's say the time for which, one process does its IO is P,  
>
>  
>
> Then 
>
>  
>
> CPU utilization = (1-P^2)  
>
> let's say P = 70 %  
>
> CPU utilization = (1-0.49) =0.51 = 51 %  

그러므로 우리는 메모리 사이즈가 증가 했을 때  CPU 사용도가 증가한다는 것을 알 수 있다.



## 2. 정적 파티셔닝 , 동적 파티셔닝

### 1. 정적  파티셔닝

하나 이상의 프로세스를 주 메모리에 로드 하는데 사용할 수 있는 가장 간단한 방법은 정적 또는 동적 메모리 할당이다. 이 기술에서 주 메모리는 같거나 다른 크기의 파티션으로 나뉘게 된다. 운영체제는 항상 첫 번째 파티션에 있고, 다른 파티션은 사용자 프로세스를 저장하는 데 사용할 수 있다. 메모리는 연속적인 방식으로 프로세스에 할당되게 된다.

정적 파티셔닝에서

1) 파티션은 겹쳐질 수 없다.

2) 프로세스는 실행을 위해 파티션에 **연속적**으로 존재해야 한다.

### 2. 정적 파티셔닝의 단점

1) 내부 단편화 (Internal Fragmentation)

![image-20210916184534963](/Users/samuel/Library/Application Support/typora-user-images/image-20210916184534963.png)

프로세스의 크기가 파티션의 전체 크기보다 작게 되면 파티션의 일부 크기가 낭비되며, 사용되지 않은 상태로 남게 된다. 이것은 메모리 낭비를 유발하고 이를 내부 단편화라고 말한다. 아래 이미지에서 볼 수 있듯이, 1MB가 낭비가 된다.

2) 외부 단편화(External Fragmentation)

다양한 파티션의 사용되지 않은 공간은 사용 가능하지만 연속적인 형태가 아닌 경우에도 프로세스를 로드하는 데 사용할 수 없다. 아래 이미지와 같이 1MB 공간은 4MB 짜리의 프로세스를 저장하는 단위로 사용할 수 없다. 프로세스를 로드할 수 있는 충분한 공간이 있음에도, 프로세스가 로드 되지 않는다.

3) 프로세스 규모의 제한(Limitation on the size of the process)

프로세스 크기가 최대 크기의 파티션 크기보다 클 경우에 프로세스를 메모리에 로드 할 수 없게 된다. 프로세스를 로드할 수 있는 충분한 공간이 있음에도 프로세스가 로드 되지 못한다.

4) 낮은 멀티프로그래밍 정도(Degree of multiprogramming is less)

멀티 프로그래밍의 정도는 단수히 동시에 메모리에 로드 할 수 있는 최대 프로세스 수를 의미한다. 정적 파티셔닝에서는 멀티 프로그래밍의 정도가 고정 되어 있고, 프로세스의 크기에 따라 파티션의 크기를 변경할 수 없기 때문이다.

![image-20210916183852271](/Users/samuel/Library/Application Support/typora-user-images/image-20210916183852271.png)

### 3. 동적 파티셔닝

정적 파티셔닝의 단점을 극복하기 위해, 동적 파티셔닝이 나오게 된다.

이 기술에서는 파티션 크기가 초기에 선언되지 않는다. 

첫번 째, 파티션은 운영 체제용으로 예약이 되어 있고, 나머지 공간은 부분으로 나뉜다. 각 파티션의 크기는 프로세스의 크기와 같다. 파티션 크기는 내부 단편화를 방지 할 수 있도록 프로세스의 필요에 따르게 된다.

![image-20210916184221057](/Users/samuel/Library/Application Support/typora-user-images/image-20210916184221057.png)

**동적 파티셔닝은 일단 내부단편화가 없다.**

고정 파티셔닝에서는 연속 메모리가 부족하여 가장 큰 파티션 크기보다 큰 프로세스를 실행 할 수 없었는데, 동적 파티셔닝은 파티션이 프로세스의 필요에 따라 생성되기 때문에 내부 단편화가 없게 된다.

**프로세스의 크기를 제한하지 않는다.**

동적 파티셔닝에서는 파티션 크기가 프로세스 크기에 따라 결정 되기 때문에 프로세스 크기가 제한되지 않는다.

**다중 프로그래밍의 정도는 동적이다.**

내부 단편화가 없기 때문에 파티션에 사용되지 않은 공간이 없으므로 더 많은 프로세스가 동시에 메모리에 로드 될 수 있다.

### 4. 동적분할의 단점

내부 단편화는 없지만 외부 단편화가 없는 것은 아니다.

![image-20210916184547073](/Users/samuel/Library/Application Support/typora-user-images/image-20210916184547073.png)

![image-20210916184617863](/Users/samuel/Library/Application Support/typora-user-images/image-20210916184617863.png)

더하여 메모리 할당이 복잡해 진다.

동적 파티셔닝은 새 프로세스가 할당 될 때 마다 파티션 크기가 변경되기 때문에 할당 및 할당 해제가 복잡해진다. OS는 모든 파티션을 추적하게 된다. 동적 메모리 할당에서 할당과 할당 해제가 매우 자주 수행되고 파티션 크기가 매번 변경되기 때문에 OS에서 모든 것을 관리하기가 어렵게 된다.

## 3. 페이징 기법

압축 방법은 모든 여유 공간이 여러 곳에서 한 곳으로 옮겨지기 때문에 많은 오버헤드가 발생하게 된다. 이 절차에 엄청난 시간이 소요되며 CPU는 이 시간 동안 유휴 상태가 된다. 압축이 외부 단편화를 방지한다는 사실에도 불구하고 시스템을 굉장히 비효율적으로 만들게 된다.

OS가 한 위치에서 다른 위치로 1바이트를 복사하려면 6개의 NS가 필요하다고 가정해 보겠다.

> 1. 1 B transfer needs 6 NS  
> 2. 256 MB transfer needs 256 X 2^20 X 6 X 10 ^ -9 secs 

더 큰 크기의 메모리 전송에는 초 단위의 엄청난 시간이 필요하다는 것이 어느 정도 입증됨에 따라 파티션의 프로세스를 보다 최적의 방식으로 로드할 수 있는 메커니즘을 찾게된다. 그러다 나온 것이 페이징이라고 하는 동적이고 유연한 메커니즘이다.

![image-20210916191437586](/Users/samuel/Library/Application Support/typora-user-images/image-20210916191437586.png)

### 페이징 기법이란 ?

페이징은 컴퓨터가 메인 메모리에서 사용하기 위해 2차 기억 장치로부터 데이터를 저장하고 검색하는 메모리 관리 기법이다. 즉 가상 기억 장치를 모두 같은 크기의 블록으로 편성하여 운영하는 기법이다. 이때의 일정한 크기를 가진 블록을 페이지라고 한다. 주소공간을 페이지 단위로 나누고 실제 기억 공간은 페이지 크기와 같은 프레임으로 나누어 사용한다.

페이징 기법이 적용된 시스템에서 가상주소는 순서쌍(p,d)로 나타 낼 수 있다. p는 가상기억장치내 참조될 항목이 속해있는 페이지 번호, d는 페이지 p 내에서 참조될 항목이 위치하고 있는 변위 이다.

어떤 프로세스가 현재 참조하고 있는 페이지가 주 기억장치 내에 있다면 그 프로세스는 수행될 수 있다. 반대로 주 기억 장치 내에 없다면 그 해당 페이지를 보조기억장치로부터 읽어와서 페이지 프레임의 한 블록에 저장한다.

### 프레임과 페이지

프레임과 페이지는 메모리를 일정한 크기의 공간으로 나누어 관리하는 단위이며, 프레임과 페이지의 크기는 같다.

- 프레임(Frame) : 물리 메모리를 일정한 크기로 나눈 블록이다.
- 페이지(Page) : 가상 메모리를 일정한 크기로 나눈 블록이다.

페이지가 하나의 프레임을 할당 받으면, 물리 메모리에 위치하게 된다. 프레임을 할당 받지 못한 페이지들은 [외부 저장장치](https://ko.wikipedia.org/w/index.php?title=외부_저장장치&action=edit&redlink=1)에 저장되며, 이때도 프레임과 같은 크기 단위로 관리된다.

### 페이지 테이블

페이지 테이블(Page Table)은 프로세스의 페이지 정보를 저장하고 있으며, 하나의 프로세스는 하나의 페이지 테이블을 가진다. 테이블은 다음과 같이 색인과 내용으로 구성되어 있다.

- 색인 : 페이지 번호.
- 내용 : 해당 페이지에 할당된 물리 메모리(프레임)의 시작 주소. 이 시작 주소와 페이지 주소를 결합하여 [물리 메모리 주소](https://ko.wikipedia.org/wiki/물리_메모리_주소)를 알 수 있다.

### 페이지의 크기

페이지의 크기는 하드웨어에 의해 정의된다. 대개 컴퓨터 구조에 따라 512 Byte에서 16MB 사이이며 2의 제곱으로 증가한다. 만약 논리 주소 공간의 크기가 2의 m승이고, 페이지가 2의 n승이라면 논리주소(logical address)의 상위 m-n Bit는 페이지 번호를 하위 n비트는 페이지 변위(offset)을 나타낸다. 하나의 페이지는 x86과 amd64에서는 4KB, ia64에서는 8KB의 크기를 가진다.

### 페이지의 동적 주소 변환

페이징 기법에서 동적주소변환 과정은 다음과 같다.

1. 수행 중인 프로세스가 가상주소 {\displaystyle V(p,d)}![{\displaystyle V(p,d)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a463cd4b10c02987a783d6cd9c88fccd1c71803e)를 참조한다.
2. 페이징 기법을 통해 페이지 {\displaystyle p}![p](https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36)가 페이지 프레임 {\displaystyle p'}![{\displaystyle p'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/40e623e3163571a220ed60ecb31aa78c24104b85)에 있음을 알아낸다.
3. 실주소 {\displaystyle r=p'+d}![{\displaystyle r=p'+d}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1b06e4070b514c3653878f14bf47758c95d5c735) 를 구한다.



![OS 페이징](https://static.javatpoint.com/operating-system/images/os-paging.png)

![OS 페이징 예](https://static.javatpoint.com/operating-system/images/os-paging-example.png)

![OS 페이징 예 2](https://static.javatpoint.com/operating-system/images/os-paging-example2.png)

### ![image-20210917161431926](/Users/samuel/Library/Application Support/typora-user-images/image-20210917161431926.png)

### 페이징의 장점

**페이징(paging)은 사용되지 않고 있는 메모리 영역이 하드 드라이브에 일시적으로 저장되는 과정을 말한다**. 물리 메모리는 하드 드라이브에 비해서 훨씬 속도가 빠르고 가격이 비싸므로 사용하고 있지 않은 메모리 공간을 파일에 저장한다는 것이 기본 개념이다. 많은 애플리케이션이 동작하고 있는 시스템을 생각해보자. 애플리케이션 중 사용하고 있지 않은 애플리케이션 전체를 물리 메모리에 유지시키는 대신 시스템은 가상 메모리 아키텍처를 이용해서 애플리케이션 메모리를 파일에 저장한다. 그리고 다시 그것이 필요한 경우에는 곧바로 메모리로 로드한다.

페이징 시스템의 가장 큰 장점은 애플리케이션이 실제 물리 메모리 용량보다 더 많이 사용할 수 있다는 것이다. 이는 물리 메모리가 충분하지 않을 때 하드 드라이브를 추가적인 보조 저장장치로 사용할 수 있기 때문이다. 하드 드라이브는 물리 메모리보다 일반적으로 1000배 정도 느리다. 그리고 운영체제는 하드 드라이브와 물리 메모리 사이에 데이터를 서로 주고 받아야 한다. 이런 이유로 애플리케이션이 실제 사용 가능한 물리 메모리 용량보다 적은 용량을 사용할 때에만 페이징이 이뤄진다.

### 페이징의 단점

페이징 테이블의 문제점은 주소결속까지 걸리는 속도 / 페이지테이블의 용량이다.

페이징 기법의 핵심은 페이지 테이블에 있고, 주소결속을 위해서는 반드시 페이지 테이블에 들려야 한다. 페이지테이블은 원래 별도의 레지스터 집합을 구성하여 활용하였으나, 페이지테이블의 요구용량이 커짐에 따라 메인메모리 상에 들어있게 되었다. 따라서 '페이지 테이블 접근', '최종 물리주소 접근'. 논리주소 하나에 대해 합쳐서 2번의 메인메모리 접근이 요구되는 것이다.

또한 페이지테이블의 시작주소를 알아내기 위해 PTBR(Page-Table Base Register)에도 매번 접근해야 한다.

즉, 페이징 기법을 사용하면 레지스터나 메모리를 접근하는 횟수가 증가될 수밖에 없고 이 때문에 필연적으로 속도가 저하되게 되어 있다.

### 정리

- **단점** : 페이지 테이블 사용으로 분할방식 대비 주소결속에서 오버헤드 발생 (속도 저하) / 페이지 테이블의 메인메모리 저장으로 공간 낭비

- cf. TLB 사용 및 페이지 테이블의 다단계 구성(구조 개선)으로 단점 완화 가능
- **장점** : 외부 단편화 문제 해결 / 페이지 공유 가능 (메모리 공간의 효과적 활용) / 페이지 보호 가능

## 4. 세그멘테이션

### 세그멘테이션 ?

- Segment : 페이지 같은 개념이지만, 프로세스를 **논리적 내용을 기반으로 나눠서** 메모리에 배치

- 프로세스를 Code, Data, Stack으로 나누는 것 역시 세그멘테이션!

- 세그먼트 테이블은 세그먼트 번호와 시작 주소(base), 세그먼트 크기(limit)를 엔트리로 가짐

  ![img](https://images.velog.io/images/nnnyeong/post/e5f07c87-9e6e-4c8f-90c9-9c92920ab486/image.png)

위 그림은 세그먼트 테이블과 프로세스가 할당된 메모리의 모습이다. 페이징 주소변환과 동일하게 d는 논리주소와 물리주소가 동일하다. 물리주소 a는 **base[s] + d** 로 계산된다.

- 논리주소 (2, 100) => 물리주소 4400번지
- 논리주소 (1, 500) => 인터럽트로 인해 프로세스 강제 종료(범위를 벗어남)

### 세그먼테이션에서 보호와 공유

먼저, 결론부터 말하면 페이징보다 세그먼테이션에서의 보호와 공유는 더 효율적이다.

보호에서는 세그먼테이션 역시 r, w, x 비트를 테이블에 추가하는데, 세그먼테이션은 논리적으로 나누기 때문에 해당 비트를 설정하기 매우 간단하고 안전하다. 페이징은 code + data + stack 영역이 있을 때 이를 일정한 크기로 나누므로 두 가지 영역이 섞일 수가 있다. 그러면 비트를 설정하기가 매우 까다롭다.

공유에서도 마찬가지다. 페이징에서는 code 영역을 나눈다해도 다른 영역이 포함될 확률이 매우 높다. 하지만 세그먼테이션은 정확히 code 영역만 나누기 때문에 더 효율적으로 공유를 수행할 수 있다.

### 세그멘테이션과 페이징

세그먼테이션은 페이징과 유사하고 보호와 공유에서는 더 나은 성능을 보여주었지만, 현재 **대부분은 페이징 기법을 사용한다.** 그 이유는 세그먼테이션에는 치명적인 단점이 있기 때문이다.

메모리 할당을 처음 시작할 때 다중 프로그래밍에서의 문제는 크기가 서로 다른 프로세스로 인해 여러 크기의 hole이 발생한다. 이로 인해 어느 hole에 프로세스를 할당하는 것에 대한 최적화 알고리즘이 존재하지 않고, 외부 단편화로 인해 메모리 낭비가 크다고 했었다.

세그먼테이션도 똑같은 문제점이 발생한다. 왜냐하면 세그먼테이션은 논리적인 단위로 나누기 때문에 세그먼트의 **크기가 다양하다.** 이로 인해 다양한 크기의 hole이 발생하므로 같은 문제가 발생한다.

결론적으로 세그먼테이션은 보호와 공유에서 효율적이고, 페이징은 외부 단편화 문제를 해결할 수 있다. 그러므로 두 가지를 합쳐서 사용하는 방법이 나왔다. 두 장점을 합치기 위해서는 **세그먼트를 페이징 기법으로 나누는 것이다.(Paged segmentation)**

하지만 이 역시 단점이 존재한다. 세그먼트와 페이지가 동시에 존재하기 때문에 주소 변환도 두 번해야한다. 즉 CPU에서 세그먼트 테이블에서 주소 변환을 하고, 그 다음 페이지 테이블에서 또 주소 변환을 해야한다.

## 5. 가상 메모리

### 가상메모리 ?

**가상 메모리** 또는 **가상 기억 장치**([문화어](https://ko.wikipedia.org/wiki/문화어): 가상기억기, virtual memory, virtual storage)는 [메모리 관리](https://ko.wikipedia.org/wiki/메모리_관리) 기법의 하나로, 기계에 실제로 이용 가능한 기억 자원을 이상적으로 추상화하여[[1\]](https://ko.wikipedia.org/wiki/가상_메모리#cite_note-1) 사용자들에게 매우 큰 (주) 메모리로 보이게 만드는 것을 말한다.[[2\]](https://ko.wikipedia.org/wiki/가상_메모리#cite_note-2) 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식이다.

이러한 방식은 [멀티태스킹](https://ko.wikipedia.org/wiki/멀티태스킹) 운영 체제에서 흔히 사용되며, 실제 [주기억장치](https://ko.wikipedia.org/wiki/주기억장치)보다 큰 메모리 영역을 제공하는 방법으로도 사용된다.

가상적으로 주어진 주소를 [가상 주소](https://ko.wikipedia.org/wiki/가상_주소)(virtual address) 또는 논리 주소(logical address) 라고 하며, 실제 메모리 상에서 유효한 주소를 [물리 주소](https://ko.wikipedia.org/wiki/물리_주소)(physical address) 또는 실주소(real address)라고 한다. 가상 주소의 범위를 가상 주소 공간, 물리 주소의 범위를 물리 주소 공간이라고 한다.

가상 주소 공간은 [메모리 관리 장치](https://ko.wikipedia.org/wiki/메모리_관리_장치)(MMU)에 의해서 물리 주소로 변환된다. 이 덕분에 프로그래머는 가상 주소 공간상에서 프로그램을 짜게 되어 프로그램이나 데이터가 주메모리상에 어떻게 존재하는지를 의식할 필요가 없어진다. 대부분의 현대적 아키텍처와 운영 체제는 가상 메모리 기능을 제공하며, 각 응용 프로그램에 더 적합한 메모리 관리를 위해 [어도비 포토샵](https://ko.wikipedia.org/wiki/어도비_포토샵)과 같은 일부 응용 프로그램은 스스로 가상 메모리를 관리하기도 한다.

가상 메모리의 개념은 [1957년](https://ko.wikipedia.org/wiki/1957년)에 발표되었다. 실제 적용된 것은 [맨체스터 대학교](https://ko.wikipedia.org/wiki/맨체스터_대학교)가 Atlas용으로 [1961년](https://ko.wikipedia.org/wiki/1961년)에 개발한 것이 최초이다. [1965년](https://ko.wikipedia.org/wiki/1965년)에 [MIT](https://ko.wikipedia.org/wiki/MIT)가 개발한 [멀틱스](https://ko.wikipedia.org/wiki/멀틱스) 시스템 이후 본격적으로 채용되기 시작했다.

가상 메모리는 크게 나누어 세그먼트(segment) 방식과 페이징 방식의 2종류가 있다. 예를 들어 [MC68000](https://ko.wikipedia.org/wiki/MC68000) 시스템에서는 68451(세그먼트(segment) 방식)과 68851(페이징 방식) 두 가지의 MMU가 준비되어 있었다.

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Virtual_memory.svg/220px-Virtual_memory.svg.png)

### 그래서 가상메모리를 사용하면

- 메모리 크기의 제약으로부터 자유로워진다.
  - 사용자 프로그램이 물리 메모리보다 커져도 실행 가능
- 병행성 및 CPU 이용률 증가
  - 사용자 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행 가능
  - 주기억장치의 용량이 확대된 것 처럼 프로그램 실행 가능
- 부가기능 제공
  - [공유 메모리](https://itwiki.kr/index.php?title=공유_메모리&action=edit&redlink=1)
  - [Memory mapped file](https://itwiki.kr/index.php?title=Memory_mapped_file&action=edit&redlink=1)
- 전반적인 속도가 느려질 수 있다.
  - 가상메모리를 사용할 경우 물리 메모리로 프로그램을 구동하는 것 보다 속도가 느림

### 수행 과정

- Virtual memory는 OS적으로 수행. HW/SW 입장에선 투명성을 가짐

1. 어떤 명령을 수행하기 위해서 필요한 page로 엑세스를 시도한다.

2. 페이지 엑세스가 불가능하다면

   (page fault)

   - OS에선 페이지가 존재하지 않는 것인지, 아직 올라오지 않은 것인지 판단한다.
   - 아직 올라오지 않은 것이라면 하드에서 해당되는 페이지를 찾는다.
   - 메모리로 올리고 다시 명령을 수행한다.

### 가상메모리 페이지 교체

- FIFO(First In First Out)
  - 가장 먼저 들어와서 가장 오래 있었던 페이지를 교체
- LRU(Least Recently Used)
  - 최근에 적게 사용된 페이지를 교체
- NUR(Not Used Recently)
  - LRU의 개선 기법으로, 참조 비트와 변형 비트를 두어 최근에 사용하지 않은 페이지를 교체
- SCR(Second Chance Replacement)
  - LRU의 개선 기법으로, 회전 주기 내에 두번 연속 사용되지 않을 경우 삭제하는 기법
- OPT(OPTimal Replacement, Belady's Algorithm)
  - 가장 오랫동안 사용하지 않을 페이지를 교체하는 기법('최적'을 상정하는 가상의 이론적 기법)
- LFU(Least Frequency Used)
  - 가장 빈번하지 않게 사용된 페이지를 교체한다.
- MFU(Most Frequency Used)
  - 가장 빈번하게 사용된 페이지를 교체한다. 구역성(Locality)에 반하는 것으로, 거의 사용되지 않는다.

## 6. 요구 페이지

앞서 페이징에 관해서 알아 보았다.

그러면 이런 페이지가 어떻게 처리 되는지에 대해서 알아보고자 한다.

먼저 A라는 Process가 존재 한다. 이 프로세스가 동작하기 위해서는 메모리에 실행 되어지는 부분의 페이지 조각이 올라 와있고, 이를 참조하여서 CPU가 연산을  할 것이다. 만약에 정말 만약에. 필요한 자원을 모두 메모리에 올리고 내리고 한다면 Context Swithcing이 발생 할때마다 어마 어마하게 많은 메모리가 IN-OUT을 해야한다 그러면.... OverHead는 이루 말할 수 없을 것이다. 여기서 알 수 있는 것은 당시에 사용될 페이지 조각만 메모리에 올라 와있으면 되는 것이다. 

이러한 개념이 **요구 페이징[Demand Paging] 개념**이다. 그러면 필요한 페이지 조각만 딲딲 메모리에 올라와 있을까? 미래를 예견하는 방법이 있지 않는 이상 완벽하게 이를 수행하는 것은 어려울 것이다. 뒤에 설명할 Locality[지역성] 이라는 개념을 이용하여서 어느정도 구현이 가능하지만 완벽하게 하기는 어려울 것이다.

**만약에 실행되어야 할 페이지 조각이 메모리에 올라가 있지 않고 Disk에만 존재하는**

**상황이 발생하면 어떠한 과정을 거쳐서 메모리에 로드 될까?**

앞에서 주절 주절 설명 했지만 알아볼 내용은 위의 내용이다.

[1] 프로세서가 프로그램이 접근하고자 하는 메모리가 유효한지 확인 하기 위해서, PageTable의 유효 비트를 확인한다. 유효 비트라 하면 해당 페이지가 메모리에 적재되어 있는지를 표시하는 Bit이다.

[2] [1]번의 검사 결과 PageTable에 해당 페이지가 올라와 있지 않다고 판단되면 **Page Fault라는 인터럽트**를 수행해서 페이지를 찾아오는 루틴을 실행한다. 위와 같이 실행하기 위해서 메모리에 페이지가 올라와야 하는데 없으면 실행 할수 없으니 얼마나 급한 일인가! 그러니 인터럽트를!

[3] 인터럽트를 처리하는 핸들러 루틴에서는 메모리에서 페이지를 로드 할 수있는 충분한 공간이 있는지 검색을 한다. 그리고 만약에 부족하다고 하면 올라 와있는   페이지 중 아웃 시킬건 아웃 시켜서 빈 공간을 확보한다. 페이지를 아웃 시키는 과정에 대해서는 http://richong.tistory.com/admin/entry/post/?id=62에 정리

[4] 새로 할당된 빈 공간에 해당 페이지의 내용을 디스크로부터 읽는다.

[5] 이제 메모리에 필요한 페이지가 올라 와 있으므로 PageTable의 유효 비트를 수정한다. 이를 통해서 프로세서가 해당 페이지를 사용 할 수있 게 된다.

[6] 이제 수행 하고자 했던 루틴을 실행 하면된다.

### 페이지 교체 알고리즘 정리

요구 페이징 시스템은 프로세스가 특정 페이지를 요구할 때 해당 페이지를 물리 메모리에 로딩한다.

메모리에 필요한 페이지가 있을 때는 잘 진행되지만, 없을 경우에는 문제가 생긴다. 프로세스가 필요로 하는 페이지가 없는 경우(page-fault) 하드 디스크에서 페이지를 찾아 빈 프레임에 로딩하는데, 여기서 또다시 ‘페이지를 올릴 빈 프레임이 없을 경우’ 란 문제에 직면할 수 있다.

이 때 사용하는 것이 새로 올릴 페이지와 교체할 희생 프레임을 찾는 알고리즘, **페이지 교체 알고리즘**이다.

> *아래의 페이지 교체 알고리즘 예시들은 각 프로세스에 프레임 3개를 주고, 지역성 교체를 가정한 것이다.*

# FIFO(first in first out)

가장 간단한 알고리즘으로, 메모리에 올라온 지 **가장 오래된** 페이지를 교체한다. 이 알고리즘을 수행하기 위해서 **각 페이지가 올라온 시간을 페이지에 기록**하거나, **페이지가 올라온 순서를 큐(Queue)에 저장**하는 방식 등을 사용할 수 있다.

![img](https://miro.medium.com/max/60/1*PisBTTZmXb2ZLHix7RdBCQ.png?q=20)

![img](https://miro.medium.com/max/1400/1*PisBTTZmXb2ZLHix7RdBCQ.png)

FIFO 알고리즘은 **이해가 쉽고**, **구현이 간단**하다. 다만 성능은 언제나 좋다고 장담할 수 없다. 위의 그림을 예시로 보자면

- **페이지 7의 경우**에는 프로세스 초기에 쓰인 후 한동안 쓰이지 않기 때문에 FIFO교체 방식이 큰 문제를 일으키지 않는다.
- **페이지 2(9번째)의 경우,** 직전 페이지 부재(page 4)로 인해 페이지 4와 페이지 2가 교체되고 난 후, 또 다시 페이지 2를 사용하기 위해 교체했던 페이지 2를 다시 불러들였다.

![img](https://miro.medium.com/max/38/1*-RmSTtbEz1td9eAKbmiIxw.png?q=20)

![img](https://miro.medium.com/max/426/1*-RmSTtbEz1td9eAKbmiIxw.png)

활발하게 사용 중인 페이지를 계속해서 교체한다면 **페이지 부재율이 높아지고 실행속도가 떨어질** 위험이 있다.

## 최적(Optimal) 페이지 교체

**앞으로 가장 오랫동안 사용되지 않을** 페이지를 교체하는 알고리즘이다.

최적 알고리즘은 수행하기 전에 선행되어야 할 전제조건이 있다. **프로세스가 앞으로 사용할 페이지를 미리 알아야 한다**는 것이다. 이 전제 조건이 실제 활용에서는 알 방법이 없기 때문에 최적 알고리즘은 **구현이 불가능한 알고리즘** 이다.

때문에 이 알고리즘은 실제 구현 목적보다 다른 알고리즘과 비교 연구 목적을 위해 주로 사용된다.

![img](https://miro.medium.com/max/60/1*MHoq4CVbRsKyXwycQanhnA.png?q=20)

![img](https://miro.medium.com/max/1400/1*MHoq4CVbRsKyXwycQanhnA.png)

최적 교체 알고리즘은 가장 오랫동안 사용되지 않을 페이지를 알고 교체하기 때문에 모든 페이지 교체 알고리즘을 통틀어 **가장 페이지 교체 수가 적다.**

- **페이지 7의 경우,** 18번째에 가서나 다시 쓰일 것을 미리 알고 있기 때문에 페이지 2와 페이지 7을 교체했다.
- **페이지 1의 경우(page3, 6번째 참조),** 현재 올라와있는 {2, 0, 1} 중 페이지 1이 14번째 참조로 가장 뒤에 쓰일 것을 알기 때문에 페이지 1과 페이지 3을 교체했다.

## LRU(least-recently-used)

**가장 오래 사용되지 않은** 페이지를 교체하는 알고리즘이다.

최적 알고리즘은 실제 구현이 불가능하므로, **최적 알고리즘의 방식과 비슷한 효과를 낼 수 있는 방법**을 사용한 것이 LRU 알고리즘이다.

최적 알고리즘은 **페이지가 사용될 시간**을 미리 알고 있다. 미리 아는 것이 불가능하다면, 과거의 데이터를 바탕으로 **페이지가 사용될 시간을 예측**하여 교체하는 것은 가능하다. 예측 방법으로 **가장 오랜 기간 사용되지 않은(least recently used)** 페이지를 교체하는 방식을 사용하는 것이다.

![img](https://miro.medium.com/max/60/1*2KmdY3wX68yaZnF6MwwTqg.png?q=20)

![img](https://miro.medium.com/max/1400/1*2KmdY3wX68yaZnF6MwwTqg.png)

LRU 알고리즘은 최적 알고리즘보다 페이지 교체 횟수가 높지만 FIFO 알고리즘 보다 효율적이다.

- **페이지 2의 경우(9번째),** 직전의 페이지 부재(page 4) 에서 *(페이지 2가 바로 다음에 사용될 것을 모르기 때문에)* {2, 0, 3} 중 가장 오랫동안 사용되지 않았던 페이지 2를 교체한다.
- **페이지 0의 경우(11번째),** 가장 오랫동안 사용되지 않았던 페이지 4를 페이지 0과 교체한다. 실제로 페이지 4는 이후에 해당 프로세스에서 참조되는 일이 없다.

LRU 알고리즘은 많은 운영체제가 채택하는 알고리즘이며, 좋은 알고리즘이라고 평가 받고있다.

## 계수-기반(Counting-Based) 페이지 교체

페이지 참조 시마다 각 페이지가 현재까지 참조된 횟수를 카운팅하는 방법이다. 이 방법을 이용해 두 가지의 알고리즘을 만들 수 있다.

### LFU(least-frequently-used)

**참조 횟수가 가장 작은 페이지를 교체**하는 알고리즘이다. 만약 교체 대상인 **페이지가 여러 개** 일 경우, LRU 알고 리즘을 따라 **가장 오래 사용되지 않은** 페이지로 교체한다.

![img](https://miro.medium.com/max/60/1*nIY4ek2yu3jsND7na4AF-Q.png?q=20)

![img](https://miro.medium.com/max/1400/1*nIY4ek2yu3jsND7na4AF-Q.png)

LFU 알고리즘은 초기에 한 페이지를 집중적으로 참조하다가 이후 다시 참조하지 않는 경우 문제가 될 수 있다. 앞으로 사용하지 않아도 초기에 사용된 참조횟수가 높아 메모리에 계속 남아있기 때문이다. 아래의 그림의 그 예시다.

![img](https://miro.medium.com/max/60/1*mBZHbLoadaZEfTMkbhcJQQ.png?q=20)

![img](https://miro.medium.com/max/1400/1*mBZHbLoadaZEfTMkbhcJQQ.png)

초기에만 쓰인 7이 메모리에 잔존해 낭비가 일어난다

### MFU(most-frequently-used)

LFU 알고리즘과 반대로, **참조 횟수가 가장 많은 페이지를 교체**하는 알고리즘이다. 참조 횟수가 적은 페이지가 최근에 사용된 것이기 때문에 앞으로 사용될 가능성이 높다는 판단이다.

![img](https://miro.medium.com/max/60/1*e5lca52SoQeiDmy4CvykIA.png?q=20)

![img](https://miro.medium.com/max/1400/1*e5lca52SoQeiDmy4CvykIA.png)

LFU와 MFU는 실제 사용에 잘 쓰이지 않는다.

- 구현에 상당한 비용이 들고,
- 최적 페이지 교체 정책을 (LRU 만큼) 제대로 유사하게 구현해내지 못하기 때문이다.

